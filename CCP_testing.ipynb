{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUiwD93JkDL8",
        "outputId": "95f00ec9-3229-4905-97ec-9c1b0a084b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define test image paths\n",
        "test_wf_path = '/content/drive/MyDrive/BioSR/Test data/CCPs/test_wf'\n",
        "test_gt_path = '/content/drive/MyDrive/BioSR/Test data/CCPs/test_gt'\n",
        "output_dir = '/content/drive/MyDrive/BioSR/Test data/CCPs/output'\n",
        "\n",
        "# Create output directory if not exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "# Define image loading function for specific folders\n",
        "def load_images_from_selected_folders(base_folder, selected_folders):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for folder in selected_folders:\n",
        "        folder_path = os.path.join(base_folder, folder)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.tif'):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "                img_tensor = transforms.ToTensor()(img)  # Convert image to tensor\n",
        "                images.append(img_tensor)\n",
        "                filenames.append(filename)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "    return images, filenames\n",
        "\n",
        "# Define folders to load\n",
        "selected_folders = ['level_01', 'level_05', 'level_09']\n",
        "\n",
        "# Load test WF images\n",
        "test_wf_images, test_wf_filenames = load_images_from_selected_folders(test_wf_path, selected_folders)\n",
        "\n",
        "# Load test GT images\n",
        "test_gt_images, test_gt_filenames = load_images_from_selected_folders(test_gt_path, [''])  # GT folder has no subfolders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_uSaq7ClPZe",
        "outputId": "3c3477dd-e89e-4f8f-fd9d-e2eff7510cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/001.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/002.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/003.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/004.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/005.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/006.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/007.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/008.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/009.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/010.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/011.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/012.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/013.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/014.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_01/015.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/001.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/002.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/003.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/004.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/005.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/006.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/007.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/008.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/009.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/010.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/011.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/012.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/013.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/014.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_05/015.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/001.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/002.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/003.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/004.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/005.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/006.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/007.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/008.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/009.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/010.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/011.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/012.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/013.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/014.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_wf/level_09/015.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/001.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/002.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/003.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/004.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/005.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/006.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/007.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/008.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/009.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/010.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/011.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/012.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/013.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/014.tif\n",
            "Loading image: /content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/015.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRIlpmTBlWD5",
        "outputId": "95d62f25-e4c2-4292-dbc7-6ca02e274746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SwinIR'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 333 (delta 6), reused 5 (delta 2), pack-reused 320 (from 1)\u001b[K\n",
            "Receiving objects: 100% (333/333), 29.84 MiB | 31.24 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.10-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from SwinIR.models.network_swinir import SwinIR\n",
        "\n",
        "# Load the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = SwinIR(\n",
        "    upscale=2,  # Upscaling factor\n",
        "    in_chans=1,  # Grayscale input\n",
        "    img_size=32,  # Input image size\n",
        "    window_size=8,  # Window size\n",
        "    depths=[4, 4, 4, 4],  # Layer depths\n",
        "    embed_dim=120,  # Embedding dimension\n",
        "    num_heads=[4, 4, 4, 4],  # Number of attention heads\n",
        "    mlp_ratio=2,  # MLP ratio\n",
        "    upsampler='pixelshuffledirect',  # Upsampler\n",
        "    resi_connection='1conv'  # Residual connection\n",
        ").to(device)\n",
        "\n",
        "# Load pre-trained model weights\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/BioSR/CCP/swinir_best_model.pth', map_location=device))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuH_YN5klpeC",
        "outputId": "3e691cab-1857-49ca-f3b2-7b811ae7a372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-5ca987ab414b>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/BioSR/CCP/swinir_best_model.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinIR(\n",
              "  (conv_first): Conv2d(1, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (patch_unembed): PatchUnEmbed()\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (layers): ModuleList(\n",
              "    (0): RSTB(\n",
              "      (residual_group): BasicLayer(\n",
              "        dim=120, input_resolution=(32, 32), depth=4\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.007)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.013)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.020)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (patch_embed): PatchEmbed()\n",
              "      (patch_unembed): PatchUnEmbed()\n",
              "    )\n",
              "    (1): RSTB(\n",
              "      (residual_group): BasicLayer(\n",
              "        dim=120, input_resolution=(32, 32), depth=4\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.027)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.033)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.040)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.047)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (patch_embed): PatchEmbed()\n",
              "      (patch_unembed): PatchUnEmbed()\n",
              "    )\n",
              "    (2): RSTB(\n",
              "      (residual_group): BasicLayer(\n",
              "        dim=120, input_resolution=(32, 32), depth=4\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.053)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.060)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.067)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.073)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (patch_embed): PatchEmbed()\n",
              "      (patch_unembed): PatchUnEmbed()\n",
              "    )\n",
              "    (3): RSTB(\n",
              "      (residual_group): BasicLayer(\n",
              "        dim=120, input_resolution=(32, 32), depth=4\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.080)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.087)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=0, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.093)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=120, input_resolution=(32, 32), num_heads=4, window_size=8, shift_size=4, mlp_ratio=2\n",
              "            (norm1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=120, window_size=(8, 8), num_heads=4\n",
              "              (qkv): Linear(in_features=120, out_features=360, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=120, out_features=120, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath(drop_prob=0.100)\n",
              "            (norm2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=120, out_features=240, bias=True)\n",
              "              (act): GELU(approximate='none')\n",
              "              (fc2): Linear(in_features=240, out_features=120, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (patch_embed): PatchEmbed()\n",
              "      (patch_unembed): PatchUnEmbed()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((120,), eps=1e-05, elementwise_affine=True)\n",
              "  (conv_after_body): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upsample): UpsampleOneStep(\n",
              "    (0): Conv2d(120, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): PixelShuffle(upscale_factor=2)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Define normalization function\n",
        "def normalize(img):\n",
        "    return (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "# Directory to save output images\n",
        "output_dir = \"/content/drive/MyDrive/BioSR/Test data/CCPs/output\"  # Replace with your output directory path\n",
        "\n",
        "# Ensure directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Process and save output images\n",
        "for i, wf_img in enumerate(test_wf_images[:len(test_gt_images)]):  # Ensure WF and GT images length match\n",
        "    wf_img = normalize(wf_img).to(device)  # Normalize and move to GPU\n",
        "\n",
        "    # Perform inference with the model\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        output = model(wf_img.unsqueeze(0))  # Add batch dimension\n",
        "        output_img = output.squeeze(0).cpu()  # Remove batch dimension and move to CPU\n",
        "\n",
        "    # Convert the output image to grayscale (single-channel)\n",
        "    if output_img.ndim == 3:  # If the output has more than one channel\n",
        "        output_img = output_img.mean(dim=0, keepdim=True)  # Take the mean across channels to convert to grayscale\n",
        "\n",
        "    # Remove the extension if it exists in the filename\n",
        "    base_filename = test_wf_filenames[i].replace('.tif', '')  # Remove '.tif' if it exists\n",
        "\n",
        "    # Save the output image in grayscale\n",
        "    output_img_path = os.path.join(output_dir, f\"{base_filename}.tif\")  # Save in .tif format\n",
        "    vutils.save_image(output_img, output_img_path, normalize=True)  # Save the image\n",
        "    print(f\"Saved output: {output_img_path}\")\n",
        "\n",
        "    # Free up memory\n",
        "    del wf_img, output, output_img  # Delete variables to free GPU memory\n",
        "    torch.cuda.empty_cache()  # Clear the cache\n",
        "\n",
        "print(\"All images processed and saved.\")\n"
      ],
      "metadata": {
        "id": "BoAHVz3zlxt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69dcd0f-c1b6-44c9-f56f-a2a12ba59fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/001.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/002.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/003.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/004.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/005.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/006.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/007.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/008.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/009.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/010.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/011.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/012.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/013.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/014.tif\n",
            "Saved output: /content/drive/MyDrive/BioSR/Test data/CCPs/output/015.tif\n",
            "All images processed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tifffile as tiff\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import numpy as np\n",
        "\n",
        "# Directories for output and ground truth\n",
        "output_dir = \"/content/drive/MyDrive/BioSR/Test data/CCPs/output/\"  # Ensure this is the correct directory path\n",
        "gt_dir = \"/content/drive/MyDrive/BioSR/Test data/CCPs/test_gt/\"    # Ensure this is the correct directory path\n",
        "\n",
        "# Retrieve actual filenames in the output folder and sort them\n",
        "output_filenames = sorted([f for f in os.listdir(output_dir) if f.endswith('.tif')])\n",
        "\n",
        "# Retrieve actual filenames in the ground truth folder and sort them\n",
        "gt_filenames = sorted([f for f in os.listdir(gt_dir) if f.endswith('.tif')])\n",
        "\n",
        "# Initialize lists to hold PSNR and SSIM values\n",
        "psnr_values = []\n",
        "ssim_values = []\n",
        "\n",
        "# Check if the number of output and ground truth images are the same\n",
        "if len(output_filenames) != len(gt_filenames):\n",
        "    raise ValueError(\"Mismatch in the number of output and ground truth images!\")\n",
        "\n",
        "# Iterate through output filenames and calculate PSNR and SSIM\n",
        "for i, output_filename in enumerate(output_filenames):\n",
        "    # Construct the output image path\n",
        "    output_img_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "    # Construct the ground truth image path using the corresponding index\n",
        "    gt_img_path = os.path.join(gt_dir, gt_filenames[i])\n",
        "\n",
        "    # Read the images\n",
        "    output_img = tiff.imread(output_img_path)\n",
        "    gt_img = tiff.imread(gt_img_path)\n",
        "\n",
        "    # Convert output image to grayscale if it has 3 channels\n",
        "    if output_img.ndim == 3:  # Check if the image has 3 dimensions (channels)\n",
        "        output_img = np.mean(output_img, axis=2)  # Convert to grayscale by averaging channels\n",
        "\n",
        "    # Ensure both images have the same dimensions\n",
        "    if gt_img.shape != output_img.shape:\n",
        "        raise ValueError(f\"Shape mismatch: Ground truth image {gt_img_path} and output image {output_img_path} have different shapes.\")\n",
        "\n",
        "    # Calculate PSNR and SSIM\n",
        "    psnr_value = psnr(gt_img, output_img)\n",
        "    ssim_value = ssim(gt_img, output_img, data_range=gt_img.max() - gt_img.min())\n",
        "\n",
        "    psnr_values.append(psnr_value)\n",
        "    ssim_values.append(ssim_value)\n",
        "\n",
        "    print(f\"Image {i+1}: PSNR = {psnr_value:.2f}, SSIM = {ssim_value:.4f}\")\n",
        "\n",
        "# Display average metrics\n",
        "average_psnr = sum(psnr_values) / len(psnr_values)\n",
        "average_ssim = sum(ssim_values) / len(ssim_values)\n",
        "\n",
        "print(f\"\\nAverage PSNR: {average_psnr:.2f}\")\n",
        "print(f\"Average SSIM: {average_ssim:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7JZUqwWOyq2",
        "outputId": "58e64c4f-d1f0-4b04-bd74-5b7a3787d896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5d1c3616b13a>:46: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
            "  psnr_value = psnr(gt_img, output_img)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1: PSNR = 24.16, SSIM = 0.7248\n",
            "Image 2: PSNR = 24.24, SSIM = 0.7805\n",
            "Image 3: PSNR = 24.45, SSIM = 0.7666\n",
            "Image 4: PSNR = 28.29, SSIM = 0.8213\n",
            "Image 5: PSNR = 24.21, SSIM = 0.7916\n",
            "Image 6: PSNR = 25.36, SSIM = 0.7939\n",
            "Image 7: PSNR = 26.91, SSIM = 0.8243\n",
            "Image 8: PSNR = 28.39, SSIM = 0.8148\n",
            "Image 9: PSNR = 25.15, SSIM = 0.7468\n",
            "Image 10: PSNR = 27.00, SSIM = 0.8411\n",
            "Image 11: PSNR = 25.74, SSIM = 0.8030\n",
            "Image 12: PSNR = 25.84, SSIM = 0.8120\n",
            "Image 13: PSNR = 24.63, SSIM = 0.8334\n",
            "Image 14: PSNR = 27.48, SSIM = 0.8561\n",
            "Image 15: PSNR = 21.48, SSIM = 0.6992\n",
            "\n",
            "Average PSNR: 25.56\n",
            "Average SSIM: 0.7939\n"
          ]
        }
      ]
    }
  ]
}